# NLTK
I’m excited to share that I’ve completed my latest NLP project, which involved applying key concepts like tokenization, stopword filtering, stemming, lemmatization, and Part of Speech (POS) tagging. This project has strengthened my understanding of how to preprocess and analyze text data effectively

1. Word Tokenization: Breaking down text into individual words for further processing.
2. Stopword Filtering: Removing common words that don’t add much value to text analysis.
3. Stemming: Reducing words to their root forms to simplify text analysis.
4. Lemmatization: Converting words to their base or dictionary form, considering their context.
5. POS Tagging: Assigning grammatical tags to words to understand their role in a sentence.
   
